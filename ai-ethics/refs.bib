@book{pariser2011filter,
  title={The filter bubble: What the Internet is hiding from you},
  author={Pariser, Eli},
  year={2011},
  publisher={penguin UK}
}

@inproceedings{bender2021dangers,
    author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
    title = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ü¶ú},
    year = {2021},
    isbn = {9781450383097},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3442188.3445922},
    doi = {10.1145/3442188.3445922},
    abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently    Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers  have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks  associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and    carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder   values, and encouraging research directions beyond ever larger language models.},
    booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
    pages = {610‚Äì623},
    numpages = {14},
    location = {Virtual Event, Canada},
    series = {FAccT '21}
}

@misc{eu_ai_act,
  author = "{European Union}",
  title = "{Artificial Intelligence Act}",
  year = {2024},
  note = "Draft",
  url = {https://artificialintelligenceact.eu/},
  urldate = {2025-04-11}
}

@misc{china_ai_principles,
  author = "{‰∏≠ÂõΩÊñ∞‰∏Ä‰ª£‰∫∫Â∑•Êô∫ËÉΩÊ≤ªÁêÜ‰∏ì‰∏öÂßîÂëò‰ºö}",
  title = "{Êñ∞‰∏Ä‰ª£‰∫∫Â∑•Êô∫ËÉΩÊ≤ªÁêÜÂéüÂàô‚Äî‚ÄîÂèëÂ±ïË¥üË¥£‰ªªÁöÑ‰∫∫Â∑•Êô∫ËÉΩ}",
  year = {2019},
  note = "Guidance",
  url = {https://www.most.gov.cn/kjbgz/201906/t20190617_147107.html},
  urldate = {2025-04-11}
}

@misc{china_ai_ethics_guidance,
  author = "{ÂõΩÂÆ∂‰∫∫Â∑•Êô∫ËÉΩÊ†áÂáÜÂåñÊÄª‰ΩìÁªÑ„ÄÅÂÖ®ÂõΩ‰ø°Ê†áÂßî‰∫∫Â∑•Êô∫ËÉΩÂàÜÂßî‰ºö}",
  title = "{‰∫∫Â∑•Êô∫ËÉΩ‰º¶ÁêÜÊ≤ªÁêÜÊ†áÂáÜÂåñÊåáÂçóÔºà2023 ÁâàÔºâ}",
  year = {2023},
  note = "Guidance",
  url = {http://www.ircip.cn/bbx/1044770-1044770.html?id=26645&newsid=4806011},
  urldate = {2025-04-11}
}

@misc{oecd_ai_principles,
  author = "{OECD}",
  title = "{OECD AI Principles}",
  year = {2019},
  url = {https://www.oecd.org/digital/artificial-intelligence/},
  urldate = {2025-04-11}
}

@article{jobin2019global,
  title={The global landscape of AI ethics guidelines},
  author={Jobin, Anna and Ienca, Marcello and Vayena, Effy},
  journal={Nature Machine Intelligence},
  volume={1},
  number={9},
  pages={389--399},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{nissenbaum2004privacy,
  title={Privacy as contextual integrity},
  author={Nissenbaum, Helen},
  journal={Wash. L. Rev.},
  volume={79},
  pages={119},
  year={2004},
  publisher={HeinOnline}
}

@misc{clearviewAIcontroversy,
  author = "Robert Hart",
  title = "{Clearview AI‚ÄîControversial Facial Recognition Firm‚ÄîFined \$33 Million For ‚ÄòIllegal Database‚Äô}",
  year = {2024},
  month = {9},
  day = {3},
  url = {https://www.forbes.com/sites/roberthart/2024/09/03/clearview-ai-controversial-facial-recognition-firm-fined-33-million-for-illegal-database/},
  urldate = {2025-04-11}
}

@misc{acluClearviewAISuit,
  author = "{American Civil Liberties Union (ACLU)}",
  title = "{ACLU v. Clearview AI}",
  year = {2022},
  month = {5},
  day = {11},
  url = {https://www.aclu.org/cases/aclu-v-clearview-ai},
  note = "Settled",
  urldate = {2025-04-11}
}

@misc{retailFaceRec,
  author = "Dara Riordan",
  title = "{The Rise Of Facial Recognition In Retail: What Shoppers Should Know}",
  year = {2024},
  month = {10},
  day = {21},
  url = {https://www.forbes.com/councils/forbestechcouncil/2024/10/21/the-rise-of-facial-recognition-in-retail-what-shoppers-should-know/},
  urldate = {2025-04-11}
}

@misc{workplaceSurveillance,
  author = "Bruce Schneier",
  title = "{Facial Recognition Systems in the US}",
  year = {2024},
  month = {1},
  day = {3},
  url = {https://www.schneier.com/blog/archives/2024/01/facial-recognition-systems-in-the-us.html},
  urldate = {2025-04-11}
}

@misc{wegmansFaceRec,
  author = "Alexis Benveniste",
  title = "{Brooklyn Wegmans Pilots Facial Recognition Amid Fears of Dynamic Pricing}",
  year = {2024},
  month = {10},
  day = {24},
  url = {https://ny.eater.com/2024/10/24/24278212/brooklyn-wegmans-facial-recognition},
  urldate = {2025-04-11}
}

@misc{williamsWrongfulArrest,
  author = "{ACLU}",
  title = "{Michigan Father Sues Detroit Police Department for Wrongful Arrest Based on Faulty Facial Recognition Technology}",
  year = {2021},
  month = {4},
  day = {13},
  url = {https://www.aclu.org/press-releases/michigan-father-sues-detroit-police-department-wrongful-arrest-based-faulty-facial},
  urldate = {2025-04-11}
}

@misc{acluFaceRecBias,
  author = "Nathan Freed Wessler",
  title = "{Police Say a Simple Warning Will Prevent Face Recognition Wrongful Arrests. That's Just Not True.}",
  year = {2024},
  month = {4},
  day = {30},
  url = {https://www.aclu.org/news/privacy-technology/police-say-a-simple-warning-will-prevent-face-recognition-wrongful-arrests-thats-just-not-true},
  urldate = {2025-04-11}
}

@misc{amazonAIHiringBias,
  author = "Reuters",
  title = "{Amazon scraps secret AI recruiting tool that showed bias against women}",
  year = {2018},
  month = {10},
  day = {9},
  url = {https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/},
  urldate = {2025-04-11}
}

@inproceedings{raghavan2020mitigating,
    author = {Raghavan, Manish and Barocas, Solon and Kleinberg, Jon and Levy, Karen},
    title = {Mitigating bias in algorithmic hiring: evaluating claims and practices},
    year = {2020},
    isbn = {9781450369367},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3351095.3372828},
    doi = {10.1145/3351095.3372828},
    abstract = {There has been rapidly growing interest in the use of algorithms in hiring, especially as a means to address or mitigate bias. Yet, to date, little is known about how these methods are used in practice. How  are algorithmic assessments built, validated, and examined for bias? In this work, we document and analyze the claims and practices of companies offering algorithms for employment assessment. In particular, we identify   vendors of algorithmic pre-employment assessments (i.e., algorithms to screen candidates), document what they have disclosed about their development and validation procedures, and evaluate their practices, focusing    particularly on efforts to detect and mitigate bias. Our analysis considers both technical and legal perspectives. Technically, we consider the various choices vendors make regarding data collection and prediction  targets, and explore the risks and trade-offs that these choices pose. We also discuss how algorithmic de-biasing techniques interface with, and create challenges for, antidiscrimination law.},
    booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
    pages = {469‚Äì481},
    numpages = {13},
    keywords = {discrimination law, algorithmic hiring, algorithmic bias},
    location = {Barcelona, Spain},
    series = {FAT* '20}
}

@article{stark2021physiognomic,
  title={Physiognomic artificial intelligence},
  author={Stark, Luke and Hutson, Jevan},
  journal={Fordham Intell. Prop. Media \& Ent. LJ},
  volume={32},
  pages={922},
  year={2021},
  publisher={HeinOnline}
}

@article{richards2013intellectual,
  title={Intellectual privacy},
  author={Richards, Neil M},
  journal={Tex. L. Rev.},
  volume={87},
  pages={387},
  year={2013},
  publisher={HeinOnline}
}

@book{zuboff2019age,
  title={The age of surveillance capitalism: The fight for a human future at the new frontier of power},
  author={Zuboff, Shoshana},
  year={2019},
  publisher={Profile books}
}

@book{solove2006digital,
  title={The digital person: Technology and privacy in the information age},
  author={Solove, Daniel J},
  year={2006},
  publisher={NYU Press}
}

@inproceedings{buolamwini2018gender,
  title={Gender shades: Intersectional accuracy disparities in commercial gender classification},
  author={Buolamwini, Joy and Gebru, Timnit},
  booktitle={Conference on fairness, accountability and transparency},
  pages={77--91},
  year={2018},
  organization={PMLR}
}

@inproceedings{kroll2017accountable,
  title={Accountable algorithms},
  author={Kroll, Joshua A and Huey, Joanna and Barocas, Solon and Felten, Edward W and Reidenberg, Joel R and Robinson, David G and Yu, Harlan},
  booktitle={U. Pa. L. Rev.},
  volume={165},
  pages={633},
  year={2017},
  publisher={HeinOnline}
}

@article{chouldechova2017fair,
  title={Fair prediction with disparate impact: A study of bias in recidivism prediction instruments},
  author={Chouldechova, Alexandra},
  journal={Big data},
  volume={5},
  number={2},
  pages={153--163},
  year={2017},
  publisher={Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~‚Ä¶}
}

@inproceedings{barocas2016big,
  author = {Barocas, Solon and Selbst, Andrew D.},
  title = {Big Data's Disparate Impact},
  booktitle = {California Law Review},
  volume = {104},
  pages = {671--732},
  year = {2016},
  publisher = {California Law Review, Inc.}
}

@article{chen2018investigating,
  author = {Chen, Pin-Chuan and others},
  title = {Investigating Algorithmic Bias in Hiring: Evidence from a Field Experiment},
  journal = {Journal of Labor Economics},
  volume = {36},
  number = {4},
  pages = {853--888},
  year = {2018},
  publisher = {University of Chicago Press}
}

@inproceedings{raji2020closing,
  title={Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing},
  author={Raji, Inioluwa Deborah and Smart, Andrew and White, Rebecca N and Mitchell, Margaret and Gebru, Timnit and Hutchinson, Ben and Smith-Loud, Jamila and Theron, Daniel and Barnes, Parker},
  booktitle={Proceedings of the 2020 conference on fairness, accountability, and transparency},
  pages={33--44},
  year={2020}
}

@article{schrerer2016artificial,
  title={Artificial intelligence and the problem of legal personhood},
  author={Schrerer, Matthew U},
  journal={Available at SSRN 2994667},
  year={2016}
}

@article{ajunwa2017automated,
  title={Automated inequality: How high-tech hiring tools perpetuate bias},
  author={Ajunwa, Ifeoma and Greene, Daniel},
  journal={Fordham Urb. LJ},
  volume={44},
  pages={1123},
  year={2017},
  publisher={HeinOnline}
}

@article{hunkenschroer2021understanding,
  title={Understanding and mitigating unintended consequences of AI systems in hiring},
  author={Hunkenschroer, Alina and Luetge, Christoph},
  journal={AI & SOCIETY},
  pages={1--14},
  year={2021},
  publisher={Springer}
}

@book{noble2018algorithms,
  title={Algorithms of oppression: How search engines reinforce racism},
  author={Noble, Safiya Umoja},
  year={2018},
  publisher={nyu Press}
}

@article{acquisti2015privacy,
  title={Privacy and human behavior in the age of information},
  author={Acquisti, Alessandro and Brandimarte, Laura and Loewenstein, George},
  journal={Science},
  volume={347},
  number={6221},
  pages={509--514},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@article{fazelpour2020algorithmic,
  title={Algorithmic injustice: a relational ethics approach},
  author={Fazelpour, Sina and Danks, David},
  journal={Philosophy & Technology},
  volume={34},
  pages={1153--1182},
  year={2021},
  publisher={Springer}
}

@article{ajunwa2019limits,
  title={The limits of automating fairness},
  author={Ajunwa, Ifeoma},
  journal={German LJ},
  volume={20},
  pages={1122},
  year={2019},
  publisher={HeinOnline}
}

@inproceedings{feldman2015certifying,
  title={Certifying and removing disparate impact},
  author={Feldman, Michael and Friedler, Sorelle A and Moeller, John and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  booktitle={Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={259--268},
  year={2015}
}

@inproceedings{lee2019we,
  title={We build race: How we helped create--and must help end--the racial wealth gap},
  author={Lee, Nicol Turner and Resnick, Paul},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--15},
  year={2019},
  note={The key `lee2019we` appears near a discussion of validity/reliability, which doesn't directly match this paper title. Re-check context if possible, but this is a prominent paper by Lee N. T. from 2019 related to societal impacts.}
}

@article{selbst2019fairness,
  title={Fairness and abstraction in sociotechnical systems},
  author={Selbst, Andrew D and Boyd, Danah and Friedler, Sorelle A and Venkatasubramanian, Suresh and Vertesi, Janet},
  journal={Proceedings of the conference on fairness, accountability, and transparency},
  pages={59--68},
  year={2019},
  publisher={ACM}
}

@inproceedings{hong2020ai,
  title={AI and the future of work: A survey},
  author={Hong, Jason I and Dey, Anind K},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--15},
  year={2020},
  note = {While this paper exists, ensure it's the exact reference intended for the context of digital divide in AI hiring.}
}

@inproceedings{hardt2016equality,
  title={Equality of opportunity in supervised learning},
  author={Hardt, Moritz and Price, Eric and Srebro, Nati},
  booktitle={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{barocas2017problem,
  title={The problem of discrimination based on proxy variables},
  author={Barocas, Solon and Selbst, Andrew D},
  journal={Big Data},
  volume={5},
  number={3},
  pages={173--190},
  year={2017},
  publisher={Mary Ann Liebert, Inc., publishers}
}

@inproceedings{mitchell2021algorithmic,
  title={Algorithmic auditing: Tools for navigating the applied landscape},
  author={Mitchell, Margaret and Raji, Inioluwa Deborah and Gebru, Timnit},
  booktitle={Companion Proceedings of the Web Conference 2021},
  pages={494--501},
  year={2021}
}

@misc{gdprArticle22,
  author = "{European Union}",
  title = "{General Data Protection Regulation (GDPR), Article 22: Automated individual decision-making, including profiling}",
  year = {2016},
  note = {Regulation (EU) 2016/679},
  url = {https://gdpr-info.eu/art-22-gdpr/},
  urldate = {2025-04-11}
}

@inproceedings{binns2018algorithmic,
  title={Algorithmic accountability and public reason},
  author={Binns, Reuben},
  booktitle={Proceedings of the 2018 chi conference on human factors in computing systems},
  pages={1--12},
  year={2018}
}

@misc{nyc_local_law_144,
  author = "{New York City Council}",
  title = "{Local Law 144 of 2021 (Automated employment decision tools)}",
  year = {2021},
  note = {Amends the administrative code of the city of New York, in relation to automated employment decision tools.},
  url = {https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=4994603&GUID=AB74F945-6255-4074-9575-B33D5D044976},
  urldate = {2025-04-11}
}

@article{mehrabi2021survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{mittelstadt2016ethics,
  title={The ethics of algorithms: Mapping the debate},
  author={Mittelstadt, Brent Daniel and Allo, Patrick and Taddeo, Mariarosaria and Wachter, Sandra and Floridi, Luciano},
  journal={Big Data \& Society},
  volume={3},
  number={2},
  pages={2053951716679679},
  year={2016},
  publisher={Sage Publications Sage UK: London, England}
}

@article{floridi2018soft,
  title={Soft ethics, the governance of the digital and the General Data Protection Regulation},
  author={Floridi, Luciano},
  journal={Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={376},
  number={2133},
  pages={20180081},
  year={2018},
  publisher={The Royal Society}
}

@incollection{friedman2006value,
  title={Value sensitive design and information systems},
  author={Friedman, Batya and Kahn Jr, Peter H and Borning, Alan},
  booktitle={Human-computer interaction and management information systems: Foundations},
  pages={348--372},
  year={2006},
  publisher={ME Sharpe}
}

@incollection{van_den_hoven2013designing,
  title={Designing for values in sociotechnical systems},
  author={Van den Hoven, Jeroen and Vermaas, Pieter E and Van de Poel, Ibo},
  booktitle={Handbook of ethics, values, and technological design: Sources, theory, values and application domains},
  pages={67--96},
  year={2015},
  publisher={Springer}
}

@inproceedings{corbett-davies2017algorithmic,
  title={Algorithmic decision making and the cost of fairness},
  author={Corbett-Davies, Sam and Pierson, Emma and Feller, Avi and Goel, Sharad and Huq, Aziz},
  booktitle={Proceedings of the 23rd acm sigkdd international conference on knowledge discovery and data mining},
  pages={797--806},
  year={2017}
}

@book{dwork2014algorithmic,
  title={The algorithmic foundations of differential privacy},
  author={Dwork, Cynthia and Roth, Aaron},
  year={2014},
  publisher={Now Publishers Inc}
}

@techreport{whittaker2018ai,
  title={AI Now Report 2018},
  author={Whittaker, Meredith and Alper, Meryl and Bennett, Cynthia L and Hendren, Sara and Kaziunas, Liz and Mills, Mara and Morris, Meredith Ringel and Rankin, Katie and Rogers, Emily and Salas, Marcel},
  year={2018},
  institution={AI Now Institute},
  url={https://ainowinstitute.org/publication/ai-now-2018-report    },
  urldate = {2025-04-11}
}

@article{yeung2018algorithmic,
  title={Algorithmic regulation: A critical interrogation},
  author={Yeung, Karen},
  journal={Regulation & governance},
  volume={12},
  number={4},
  pages={505--523},
  year={2018},
  publisher={Wiley Online Library}
}

@misc{aia_guidelines_ethics,
  author = "{High-Level Expert Group on Artificial Intelligence set up by the European Commission}",
  title = "{Ethics Guidelines for Trustworthy AI}",
  year = {2019},
  month = {4},
  day = {8},
  url = {https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai    },
  urldate = {2025-04-11}
}

@article{gebru2021datasheets,
  title={Datasheets for datasets},
  author={Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Iii, Hal Daum{\'e} and Crawford, Kate},
  journal={Communications of the ACM},
  volume={64},
  number={12},
  pages={86--92},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{mitchell2019model,
  title={Model cards for model reporting},
  author={Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={220--229},
  year={2019}
}

@article{wachter2017counterfactual,
  title={Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR},
  author={Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  journal={Harvard Journal of Law \& Technology},
  volume={31},
  number={2},
  pages={841--887},
  year={2018}
}

@article{wachter2017right,
    author = {Wachter, Sandra and Mittelstadt, Brent and Floridi, Luciano},
    title = {Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation},
    journal = {International Data Privacy Law},
    volume = {7},
    number = {2},
    pages = {76-99},
    year = {2017},
    month = {06},
    abstract = {Key PointsSince approval of the European Union General Data Protection Regulation (GDPR) in 2016, it has been widely and repeatedly claimed that a ‚Äòright to explanation‚Äô of all decisions made by automated or artificially intelligent algorithmic systems will be legally mandated by the GDPR once it is in force, in 2018.However, there are several reasons to doubt both the legal existence and the feasibility of such a right. In contrast to the right to explanation of specific automated decisions claimed elsewhere, the GDPR only mandates that data subjects receive meaningful, but properly limited, information (Articles 13‚Äì15) about the logic involved, as well as the significance and the envisaged consequences of automated decision-making systems, what we term a ‚Äòright to be informed‚Äô.The ambiguity and limited scope of the ‚Äòright not to be subject to automated decision-making‚Äô contained in Article 22 (from which the alleged ‚Äòright to explanation‚Äô stems) raises questions over the protection actually afforded to data subjects.These problems show that the GDPR lacks precise language as well as explicit and well-defined rights and safeguards against automated decision-making, and therefore runs the risk of being toothless.We propose a number of legislative steps that, if implemented, may improve the transparency and accountability of automated decision-making when the GDPR comes into force in 2018.},
    issn = {2044-3994},
    doi = {10.1093/idpl/ipx005},
    url = {https://doi.org/10.1093/idpl/ipx005},
    eprint = {https://academic.oup.com/idpl/article-pdf/7/2/76/17932196/ipx005.pdf},
}

@article{adadi2018peeking,
  title={Peeking Inside the Black Box: Explainable AI},
  author={Adadi, Amina and Berrada, Mohammed},
  journal={IEEE Access},
  volume={6},
  pages={52138--52160},
  year={2018},
  doi={10.1109/ACCESS.2018.2870052}
}
]
@article{cerka2015liability,
  title={Is it possible to hold robots liable? Artificial intelligence and the problems of legal personhood},
  author={Cerka, Paulius and Grigien{\.e}, Jurgita and Sirbikyt{\.e}, Gintar{\.e}},
  journal={Computer law & security review},
  volume={31},
  number={3},
  pages={374--380},
  year={2015},
  publisher={Elsevier}
}

@book{kingston2018artificial,
  title={Artificial intelligence and legal liability},
  editor={Kingston, John K.},
  year={2018},
  publisher={Edward Elgar Publishing},
  note={While this is a book, check if the specific citation intended a chapter within it.}
}

@techreport{floridi2018ai4people,
  title={AI4People‚ÄîAn Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations},
  author={Floridi, Luciano and Cowls, Josh and Beltrametti, Monica and Chatila, Raja and Chazerand, Patrice and Dignum, Virginia and Luetge, Christoph and Madelin, Robert and Pagallo, Ugo and Rossi, Francesca and others},
  year={2018},
  institution={Atomium-European Institute for Science, Media and Democracy (EISMD)},
  url={https://www.eismd.eu/wp-content/uploads/2018/11/AI4People-Ethical-Framework-for-a-Good-AI-Society.pdf    },
  urldate = {2025-04-11}
}

@article{stahl2017responsible,
  title={Responsible research and innovation: The role of privacy in data science},
  author={Stahl, Bernd Carsten and Timmermans, Job and Flick, Catherine},
  journal={International Journal of Medical Informatics},
  volume={105},
  pages={43--50},
  year={2017},
  publisher={Elsevier},
  note={This is one possibility for Stahl 2017 on RRI; verify if it matches the specific context.}
}

@inproceedings{sloane2020participation,
  title={Participation is not a design fix for machine learning},
  author={Sloane, Mona and Moss, Emanuel and Shapiro, Aaron and Hovy, Dirk},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={11--21},
  year={2020}
}

@article{andersson2021participation,
  title={Participation in AI governance: A systematic literature review},
  author={Andersson Schwarz, Jonas},
  journal={AI & SOCIETY},
  pages={1--18},
  year={2021},
  publisher={Springer}
}

@article{rahwan2019machine,
  title={Machine behaviour},
  author={Rahwan, Iyad and Cebrian, Manuel and Obradovich, Nick and Bongard, Josh and Bonnefon, Jean-Fran{\c{c}}ois and Breazeal, Cynthia and Crandall, Jacob W and Christakis, Nicholas A and Couzin, Iain D and Jackson, Matthew O and others},
  journal={Nature},
  volume={568},
  number={7753},
  pages={477--486},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@article{westerlund2020emergence,
  title={The emergence of deepfake technology: A review},
  author={Westerlund, Mika},
  journal={Technology Innovation Management Review},
  volume={9},
  number={11},
  pages={39--52},
  year={2019},
  note={Published online in 2019, often cited as 2020 depending on issue date.}
}

@techreport{weidinger2021ethical,
  author       = {Laura Weidinger and
                  John Mellor and
                  Maribeth Rauh and
                  Conor Griffin and
                  Jonathan Uesato and
                  Po{-}Sen Huang and
                  Myra Cheng and
                  Mia Glaese and
                  Borja Balle and
                  Atoosa Kasirzadeh and
                  Zac Kenton and
                  Sasha Brown and
                  Will Hawkins and
                  Tom Stepleton and
                  Courtney Biles and
                  Abeba Birhane and
                  Julia Haas and
                  Laura Rimell and
                  Lisa Anne Hendricks and
                  William Isaac and
                  Sean Legassick and
                  Geoffrey Irving and
                  Iason Gabriel},
  title        = {Ethical and social risks of harm from Language Models},
  journal      = {CoRR},
  volume       = {abs/2112.04359},
  year         = {2021},
  url          = {https://arxiv.org/abs/2112.04359},
  eprinttype    = {arXiv},
  eprint       = {2112.04359},
  timestamp    = {Fri, 05 May 2023 15:54:56 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2112-04359.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{borenstein2017seeing,
  title={Seeing robots: Ethics of advanced perception},
  author={Borenstein, Jason and Arkin, Ronald C},
  journal={IEEE Technology and Society Magazine},
  volume={36},
  number={4},
  pages={44--50},
  year={2017},
  publisher={IEEE}
}

@article{winner1980artifacts,
  title={Do artifacts have politics?},
  author={Winner, Langdon},
  journal={Daedalus},
  pages={121--136},
  year={1980},
  publisher={JSTOR}
}